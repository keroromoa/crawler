{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "import urllib3\n",
    "import jieba\n",
    "import csv\n",
    "\n",
    "URLlist1 = \"https://www.518.com.tw/job-index-P-1.html?i=1&am=1&ad=java\"\n",
    "resplist1 = requests.get(URLlist1)\n",
    "souplist1 = BeautifulSoup(resplist1.text, 'lxml') # Beautifulsoup Object\n",
    "souplistcontent1 = souplist1.select('#listContent')\n",
    "soupanchor1 = ''.join(str(e) for e in souplistcontent1)\n",
    "soupanchorhref1 = BeautifulSoup(soupanchor1, \"lxml\")\n",
    "\n",
    "URLlist2 = \"https://www.518.com.tw/job-index-P-2.html?i=1&am=1&ad=java\"\n",
    "resplist2 = requests.get(URLlist2)\n",
    "souplist2 = BeautifulSoup(resplist2.text, 'lxml') # Beautifulsoup Object\n",
    "souplistcontent2 = souplist2.select('#listContent')\n",
    "soupanchor2 = ''.join(str(e) for e in souplistcontent2)\n",
    "soupanchorhref2 = BeautifulSoup(soupanchor2, \"lxml\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "anchor518 = []\n",
    "for link in soupanchorhref1.find_all('a'):\n",
    "    anchor = link.get('href')\n",
    "    anchor518.append(anchor)\n",
    "for link in soupanchorhref2.find_all('a'):\n",
    "    anchor = link.get('href')\n",
    "    anchor518.append(anchor)\n",
    "    \n",
    "anchor518finallist = [s for s in anchor518 if 'job' in s]\n",
    "\n",
    "counter = {}\n",
    "for i in anchor518finallist:\n",
    "\n",
    "    URL = i\n",
    "    resp = requests.get(URL)\n",
    "    resp.text\n",
    "\n",
    "    soup1 = BeautifulSoup(resp.text, 'lxml') # Beautifulsoup Object\n",
    "    soup2 = BeautifulSoup(resp.text, \"lxml\")\n",
    "\n",
    "\n",
    "\n",
    "    data = soup1.find_all('script', type=\"text/javascript\")\n",
    "    type(data[4])\n",
    "\n",
    "    paragraphs = []\n",
    "    for x in data[4]:\n",
    "        paragraphs.append(x)\n",
    "\n",
    "        jobItem1 = ''.join(str(e) for e in paragraphs)\n",
    "    jobLocid = jobItem1.split()\n",
    "    \n",
    "\n",
    "\n",
    "    jobItem2 = BeautifulSoup(''.join(str(e) for e in soup2.select('.job-title')), \"lxml\")\n",
    "    strJobIndex = jobItem2.select_one('strong').text\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    jieba.load_userdict('human_bank.txt')\n",
    "\n",
    "\n",
    "    seg_list = jieba.cut(strJobIndex)\n",
    "    result = (\" \".join(seg_list))\n",
    "    jobJieba = result.split()\n",
    "    \n",
    "    for word in jobJieba:\n",
    "        word = word.lower().replace(':', '').replace('.', '').replace(',', '')\n",
    "        if word in counter:\n",
    "            counter[word] += 1\n",
    "        else:\n",
    "            counter[word] = 1\n",
    "\n",
    "jobResult = []\n",
    "for word, cnt in counter.items():\n",
    "    jobResult.append((word,cnt))\n",
    "    \n",
    "def get_count(x):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        x -> list\n",
    "    retrun:\n",
    "        val -> value we want to sort with\n",
    "    \"\"\"\n",
    "    return x[1]\n",
    "\n",
    "def get_word(x):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        x -> list\n",
    "    retrun:\n",
    "        val -> value we want to sort with\n",
    "    \"\"\"\n",
    "    return x[0]\n",
    "\n",
    "jobSortedResult = sorted(jobResult, key=get_count, reverse=True)\n",
    "\n",
    "f = open(\"518crawler.csv\",\"w\")\n",
    "w = csv.writer(f)\n",
    "w.writerows(jobSortedResult)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APP程式設計師\n",
      "Java開發工程師\n",
      "系統開發工程師\n",
      "軟體工程師\n",
      "軟體設計工程師\n",
      "知名線上博弈集團 -徵聘 Java開發工程師\n",
      "外商線上娛樂集團  徵聘  JAVA Developer  2名  工作地點 菲律賓\n",
      "Android Developer\n",
      "集團公司 徵求jave工程師 具大型開發經驗者佳mk\n",
      "正職JAVA程式設計師HRI\n",
      "台北市南港區 本土壽險公司JAVA工程師\n",
      "Android Engineer\n",
      "Backend Engineer\n",
      "軟體工程師\n",
      "Java 資深工程師\n",
      "程式設計師\n",
      "PHP網頁程式工程師\n",
      "PHP工程師\n",
      "資訊人員\n",
      "系統分析師\n",
      "Android 工程師\n",
      "Android 高級工程師\n",
      "Java 開發工程師\n",
      "App開發工程師-台中-\n",
      "ERP軟體程式設計師\n",
      "系統程式設計工程師\n",
      "軟體工程師\n",
      "Android 開發人員\n",
      "程式設計助理工程師\n",
      "Java工程師-金融科技服務事業處(技術4組)\n",
      "物聯網 - JAVA工程師\n",
      "系統整合工程師\n",
      "JAVA工程師\n",
      "全端 Java 開發工程師\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "import urllib3\n",
    "import jieba\n",
    "import csv\n",
    "\n",
    "URLlist1 = \"https://www.518.com.tw/job-index-P-1.html?i=1&am=1&ad=java\"\n",
    "resplist1 = requests.get(URLlist1)\n",
    "souplist1 = BeautifulSoup(resplist1.text, 'lxml') # Beautifulsoup Object\n",
    "souplistcontent1 = souplist1.select('#listContent')\n",
    "soupanchor1 = ''.join(str(e) for e in souplistcontent1)\n",
    "soupanchorhref1 = BeautifulSoup(soupanchor1, \"lxml\")\n",
    "\n",
    "URLlist2 = \"https://www.518.com.tw/job-index-P-2.html?i=1&am=1&ad=java\"\n",
    "resplist2 = requests.get(URLlist2)\n",
    "souplist2 = BeautifulSoup(resplist2.text, 'lxml') # Beautifulsoup Object\n",
    "souplistcontent2 = souplist2.select('#listContent')\n",
    "soupanchor2 = ''.join(str(e) for e in souplistcontent2)\n",
    "soupanchorhref2 = BeautifulSoup(soupanchor2, \"lxml\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "anchor518 = []\n",
    "for link in soupanchorhref1.find_all('a'):\n",
    "    anchor = link.get('href')\n",
    "    anchor518.append(anchor)\n",
    "for link in soupanchorhref2.find_all('a'):\n",
    "    anchor = link.get('href')\n",
    "    anchor518.append(anchor)\n",
    "    \n",
    "anchor518finallist = [s for s in anchor518 if 'job' in s]\n",
    "\n",
    "counter = {}\n",
    "for i in anchor518finallist:\n",
    "\n",
    "    URL = i\n",
    "    resp = requests.get(URL)\n",
    "    resp.text\n",
    "\n",
    "    soup1 = BeautifulSoup(resp.text, 'lxml') # Beautifulsoup Object\n",
    "    soup2 = BeautifulSoup(resp.text, \"lxml\")\n",
    "\n",
    "\n",
    "\n",
    "    data = soup1.find_all('script', type=\"text/javascript\")\n",
    "    type(data[4])\n",
    "\n",
    "    paragraphs = []\n",
    "    for x in data[4]:\n",
    "        paragraphs.append(x)\n",
    "\n",
    "        jobItem1 = ''.join(str(e) for e in paragraphs)\n",
    "    jobLocid = jobItem1.split()\n",
    "    \n",
    "\n",
    "\n",
    "    jobItem2 = BeautifulSoup(''.join(str(e) for e in soup2.select('.job-title')), \"lxml\")\n",
    "    strJobIndex = jobItem2.select_one('strong').text\n",
    "    print(strJobIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anchor518finallist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
